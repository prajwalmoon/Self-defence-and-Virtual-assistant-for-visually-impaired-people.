{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Traning_Scene_detection_keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxNf7H/YdQn//fn3sU+ZSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrithvirajChauhan1/Self-defence-and-Virtual-assistant-for-visually-impaired-people./blob/main/Traning_Scene_detection_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpcw--oKKsa2"
      },
      "source": [
        "%Importing libraries\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAQyWwgKKYMs"
      },
      "source": [
        "\n",
        "\n",
        "%Initializing the nueral network\n",
        "classifier = Sequential()\n",
        "\n",
        "%Convolution to reduce the dimensions\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (256, 256, 3), activation=’relu’))\n",
        "\n",
        "%2x2 for max pooling. This enables us to reduce the \n",
        "%size of the feature map while not losing important image information.\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "%Resizing the image into one column\n",
        "classifier.add(Flatten())\n",
        "\n",
        "%output_dim is the number of nodes of the hidden network\n",
        "classifier.add(Dense(output_dim = 128, activation=’relu’))\n",
        "\n",
        "%For the output we use sigmoid activation fucn\n",
        "classifier.add(Dense(output_dim=1, activation=’sigmoid’))\n",
        "\n",
        "%We are using binary classifier and compiling the CNN for gradient descent we are using optimizer\n",
        "classifier.compile(optimizer=’adam’, loss=’binary_crossentropy’,metrics=[‘accuracy’])\n",
        "\n",
        "%For scaling , zooming , resizing purposes & making pixel values between 1 and 0\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "%rescale the pixels of the test set so that they are between zero and one. \n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "%The trainng batch\n",
        "training_set = train_datagen.flow_from_directory(‘training_set’, target_size=(256, 256), batch_size=32, class_mode=’binary’)\n",
        "\n",
        "%For test batch\n",
        "test_set = test_datagen.flow_from_directory(‘test_set’, target_size=(64, 64), batch_size=32, class_mode=’binary’)\n",
        "\n",
        "%\n",
        "classifier.fit_generator(training_set, steps_per_epoch=5000, epochs=25, validation_data=test_set, nb_val_samples=1000)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08vjcm6lKwBh"
      },
      "source": [
        "%Now image testing\n",
        "test_image = image.load_img(‘brain_image1.jpg’, target_size=(256, 256))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "prediction = classifier.predict(test_image)\n",
        "training_set.class_indices  %getting the results according to the train and test sets provided Using Deep Nueral networks\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}